import urllib.parse
import json
import os
from .database import db_manager
from .config import settings
import unicodedata
import requests


GOOGLE_API_KEY = getattr(settings, "GOOGLE_MAPS_API_KEY", None)
# Import Search Engine
try:
    from src.search_engine import StoreSearchEngine
except ImportError:
    StoreSearchEngine = None

class StoreService:
    def __init__(self):
        print("Dang tai RAG Engine...")
        self.rag = StoreSearchEngine() if StoreSearchEngine else None

    def search_products(self, query: str, limit: int = 10):
        """
        T√¨m ki·∫øm s·∫£n ph·∫©m b·∫±ng RAG Vector + SQL.
        Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng Markdown bao g·ªìm: ·∫¢nh, Gi√°, ƒê√°nh gi√°, Th√¥ng s·ªë.
        """
        if not self.rag: return "H·ªá th·ªëng t√¨m ki·∫øm ƒëang b·∫£o tr√¨."

        # 1. T√¨m ki·∫øm Vector (T√¨m theo √Ω hi·ªÉu)
        results = self.rag.search(query, k=limit)

        # Debug log
        print(f"DEBUG: RAG search completed for '{query}', results: {len(results) if results else 0}")

        if not results: return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o ph√π h·ª£p."
        
        conn = db_manager.get_connection()
        cursor = conn.cursor()
        
        response_text = ""
        print(f"\n--- DEBUG TIM ANH ({len(results)} ket qua) ---")
        
        for doc in results:
            name = doc.metadata.get('name')
            
            # [QUAN TR·ªåNG] L·∫•y th√™m c·ªôt 'rag_content' ƒë·ªÉ hi·ªÉn th·ªã th√¥ng s·ªë k·ªπ thu·∫≠t cho Frontend V4
            # D√πng LIKE ƒë·ªÉ t√¨m ki·∫øm linh ho·∫°t h∆°n (tr√°nh l·ªói l·ªách t√™n)
            cursor.execute("SELECT price_int, image_url, discount_rate, rating_avg, review_count, rag_content FROM products WHERE name LIKE ? LIMIT 1", (f"%{name}%",))
            row = cursor.fetchone()
            
            if row:
                original_price, img_url, discount, rating, reviews, specs_text = row
                
                print(f"Tim thay SQL: {name[:50]} | Anh: {str(img_url)[:30]}...")

                # 1. X·ª≠ l√Ω URL ·∫£nh an to√†n
                if img_url and len(str(img_url)) > 5:
                    img_url = urllib.parse.quote(img_url, safe=":/?#[]@!$&'()*+,;=")
                else:
                    img_url = "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzAwIiBoZWlnaHQ9IjMwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBmaWxsPSIjRjNGNEY2Ii8+PHRleHQgeD0iNTAlIiB5PSI1MCUiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxOCIgZmlsbD0iIzk5OSIgdGV4dC1hbmNob3I9Im1pZGRsZSIgZHk9Ii4zZW0iPk5vIEltYWdlPC90ZXh0Pjwvc3ZnPg=="

                # 2. X·ª≠ l√Ω d·ªØ li·ªáu hi·ªÉn th·ªã (Rating, Stars)
                rating = rating if rating else 0
                reviews = reviews if reviews else 0
                star_icon = "‚≠ê" * int(round(rating)) if rating > 0 else ""

                # 3. X·ª≠ l√Ω th√¥ng s·ªë k·ªπ thu·∫≠t (C·∫Øt ng·∫Øn cho g·ªçn ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp tr√™n Card)
                if specs_text:
                    # Lo·∫°i b·ªè ph·∫ßn t√™n l·∫∑p l·∫°i ·ªü ƒë·∫ßu chu·ªói rag_content
                    # V√≠ d·ª•: "S·∫£n ph·∫©m: iPhone 15. C·∫•u h√¨nh:..." -> "C·∫•u h√¨nh:..."
                    short_specs = specs_text.replace(f"S·∫£n ph·∫©m: {name}.", "").strip()
                    # L·∫•y kho·∫£ng 150 k√Ω t·ª± ƒë·∫ßu ti√™n
                    short_specs = short_specs[:160] + "..." if len(short_specs) > 160 else short_specs
                else:
                    short_specs = "ƒêang c·∫≠p nh·∫≠t..."

                # 4. T√≠nh gi√° khuy·∫øn m√£i
                final_price = original_price * (1 - discount/100)
                
                # Logic: Lu√¥n b·∫Øt ƒë·∫ßu b·∫±ng icon ti·ªÅn ƒë·ªÉ Frontend d·ªÖ b·∫Øt
                if discount > 0:
                    price_str = f"{final_price:,.0f}ƒë"
                else:
                    price_str = f"{original_price:,.0f}ƒë"
                
                # 5. T·∫°o Markdown chu·∫©n (Frontend b·∫Øt bu·ªôc ph·∫£i theo format n√†y)
                # QUAN TR·ªåNG: Ph·∫£i c√≥ ch·ªØ "Gi√°:", "ƒê√°nh gi√°:", "Th√¥ng s·ªë:", "M√¥ t·∫£:"
                response_text += f"""
**{name}**
![{name}]({img_url})
- üí∞ Gi√°: {price_str}
- ‚≠ê ƒê√°nh gi√°: {rating}/5 ({reviews} ƒë√°nh gi√°)
- ‚öôÔ∏è Th√¥ng s·ªë: {short_specs}
- üìù M√¥ t·∫£: {doc.page_content[:150]}...
---
"""

        # Debug log
        print(f"DEBUG: Returning response for '{query}', length: {len(response_text)}")

        return response_text.strip()

    def check_stock(self, product_name: str):
        """Ki·ªÉm tra t·ªìn kho"""
        conn = db_manager.get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT name, price_int, stock, discount_rate FROM products WHERE name LIKE ?", (f"%{product_name}%",))
        item = cursor.fetchone()
        conn.close()
        
        if item:
            name, price, stock, discount = item
            final_price = price * (1 - discount/100)
            status = f"CON {stock} chiec" if stock > 0 else "HET HANG"
            return f"S·∫£n ph·∫©m **{name}**\n- T√¨nh tr·∫°ng: {status}\n- Gi√° hi·ªán t·∫°i: {final_price:,.0f}ƒë (ƒê√£ gi·∫£m {discount}%)"
        return "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†y."

    def remove_accents(self, input_str):
        if not input_str: return ""
        nfkd_form = unicodedata.normalize('NFKD', input_str)
        return "".join([c for c in nfkd_form if not unicodedata.combining(c)])

    def find_nearest_store(self, lat: float, lng: float):
        """
        T√¨m c·ª≠a h√†ng g·∫ßn nh·∫•t d√πng Google Places API (v1).
        Tr·∫£ v·ªÅ: ƒê·ªãa ch·ªâ, to·∫° ƒë·ªô, ƒëi·ªán tho·∫°i, website, gi·ªù ho·∫°t ƒë·ªông, rating, review, ti·ªán √≠ch.
        """
        api_key = getattr(settings, "PLACES_API_KEY", None)
        if not api_key:
            return "Ch∆∞a c·∫•u h√¨nh PLACES_API_KEY!"
        
        url = "https://places.googleapis.com/v1/places:searchText"
        headers = {
            'Content-Type': 'application/json',
            'X-Goog-Api-Key': api_key,
            'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,'
                             'places.location,places.rating,places.userRatingCount,'
                             'places.websiteUri,places.regularOpeningHours,places.types,'
                             'places.internationalPhoneNumber,places.reviews,places.accessibilityOptions'
        }
        
        payload = {
            "textQuery": "CellphoneS",
            "languageCode": "vi",
            "locationBias": {
                "rectangle": {
                    "low": {
                        "latitude": lat - 0.01,  # Kho·∫£ng 1km
                        "longitude": lng - 0.01
                    },
                    "high": {
                        "latitude": lat + 0.01,
                        "longitude": lng + 0.01
                    }
                }
            }
        }
        
        try:
            # G·ªçi API t√¨m ki·∫øm
            resp = requests.post(url, headers=headers, json=payload, timeout=10)
            resp.raise_for_status()
            data = resp.json()
            
            if not data.get("places"):
                return "Kh√¥ng t√¨m th·∫•y c·ª≠a h√†ng g·∫ßn b·∫°n."
                
            # L·∫•y c·ª≠a h√†ng g·∫ßn nh·∫•t
            shop = data["places"][0]
            
            # Tr√≠ch xu·∫•t th√¥ng tin
            name = shop.get("displayName", {}).get("text", "N/A")
            address = shop.get("formattedAddress", "N/A")
            location = shop.get("location", {})
            lat_ = location.get("latitude")
            lng_ = location.get("longitude")
            rating = shop.get("rating", "?")
            user_ratings_total = shop.get("userRatingCount", 0)
            phone = shop.get("internationalPhoneNumber", "N/A")
            website = shop.get("websiteUri", "N/A")
            
            # X·ª≠ l√Ω gi·ªù m·ªü c·ª≠a
            opening_hours = []
            if "regularOpeningHours" in shop:
                for day in shop["regularOpeningHours"].get("weekdayDescriptions", []):
                    opening_hours.append(day)
            
            # X·ª≠ l√Ω ƒë√°nh gi√°
            reviews = shop.get("reviews", [])
            review_texts = "".join(
                [f"- {r.get('authorAttribution', {}).get('displayName', '·∫®n danh')}: "
                 f"'{r.get('originalText', {}).get('text', '')[:100]}...'\n" 
                 for r in reviews[:3]]
            ) if reviews else "Ch∆∞a c√≥ ƒë√°nh gi√° n·ªïi b·∫≠t."
            
            # X·ª≠ l√Ω ti·ªán √≠ch
            amenities = []
            if shop.get("accessibilityOptions", {}).get("wheelchairAccessibleParking"):
                amenities.append("C√≥ l·ªëi cho xe lƒÉn")
            if "parking" in str(shop.get("types", [])).lower():
                amenities.append("C√≥ b√£i ƒë·ªó xe")
            if "wifi" in str(shop.get("types", [])).lower():
                amenities.append("C√≥ Wi-Fi")
                
            # T·∫°o link Google Maps
            map_link = f"https://www.google.com/maps/search/?api=1&query={lat_},{lng_}"
            
            # T·∫°o k·∫øt qu·∫£
            result = f"""
üè† **{name}**
- ƒê·ªãa ch·ªâ: {address}
- To·∫° ƒë·ªô: ({lat_}, {lng_})
- ƒêi·ªán tho·∫°i: {phone}
- Website: {website}
- ‚òÖ ƒêi·ªÉm ƒë√°nh gi√°: {rating}/5 (T·ªïng: {user_ratings_total} ƒë√°nh gi√°)
- Gi·ªù m·ªü c·ª≠a:
{chr(10).join(opening_hours) if opening_hours else 'Ch∆∞a c√≥ th√¥ng tin.'}
- Ti·ªán √≠ch: {', '.join(amenities) if amenities else 'ƒêang c·∫≠p nh·∫≠t.'}
- ƒê√°nh gi√° ng∆∞·ªùi d√πng n·ªïi b·∫≠t:
{review_texts}
- üìç [Xem tr√™n Google Maps]({map_link})
"""
            return result.strip()
            
        except requests.exceptions.RequestException as e:
            return f"L·ªói k·∫øt n·ªëi ƒë·∫øn Google Places API: {str(e)}"
        except Exception as e:
            return f"L·ªói khi l·∫•y th√¥ng tin c·ª≠a h√†ng: {str(e)}"




def find_stores(self, location: str):
        """
        T√¨m c·ª≠a h√†ng theo t√™n ƒë·ªãa ƒëi·ªÉm (Qu·∫≠n/Huy·ªán)
        """
        print(f"üìç ƒêang t√¨m c·ª≠a h√†ng t·∫°i: {location}")
        
        # D√πng l·∫°i c·∫•u h√¨nh c·ªßa SerpAPI nh∆∞ng thay ƒë·ªïi tham s·ªë t√¨m ki·∫øm
        params = {
            "engine": "google_maps",
            "q": f"CellphoneS {location}", # T√¨m "CellphoneS + C·∫ßu Gi·∫•y"
            "type": "search",
            "api_key": settings.SERP_API_KEY,
            "hl": "vi"
        }

        try:
            response = requests.get("https://serpapi.com/search.json", params=params, timeout=10)
            data = response.json()
            results = data.get("local_results", [])

            if not results:
                return f"Khong tim thay cua hang CellphoneS nao o khu vuc '{location}' a."

            # L·∫•y t·ªëi ƒëa 3 c·ª≠a h√†ng ƒë·ªÉ hi·ªÉn th·ªã cho g·ªçn
            response_text = f"üìç **Danh s√°ch c·ª≠a h√†ng t·∫°i {location}:**\n\n"
            
            for store in results[:3]:
                name = store.get("title")
                address = store.get("address")
                rating = store.get("rating", "4.5")
                
                # T·∫°o link Google Maps
                gps = store.get("gps_coordinates", {})
                lat = gps.get("latitude")
                lng = gps.get("longitude")
                map_url = f"http://maps.google.com/?q={lat},{lng}"

                response_text += f"üè† **{name}**\n- üìç {address}\n- ‚≠ê {rating}/5\n- üó∫Ô∏è [Xem b·∫£n ƒë·ªì]({map_url})\n\n"
            
            return response_text

        except Exception as e:
            return f"Loi tim kiem cua hang: {str(e)}"


store_service = StoreService()